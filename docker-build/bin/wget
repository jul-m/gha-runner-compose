#!/bin/sh
########################################################################################################################
##  File:  docker-build/bin/wget
##  Desc:  wget wrapper for gha-runner-compose builds: Adds caching and optional GitHub authentication
########################################################################################################################

set -eu

CACHE_DIR="${GHA_FETCH_CACHE_DIR:-/var/cache/gha-download-cache}"

# Locate the first real wget binary in PATH that isn't this wrapper.
find_real() {
  name="$1"
  self="$0"
  for d in /usr/local/bin /usr/bin /bin /opt/homebrew/bin /usr/local/sbin /usr/sbin /sbin; do
    if [ -x "$d/$name" ] && [ "$d/$name" != "$self" ]; then
      printf '%s' "$d/$name"
      return 0
    fi
  done
  cand="$(command -v "$name" 2>/dev/null || true)"
  if [ "${cand:-}" != "" ] && [ "$cand" != "$self" ]; then
    printf '%s' "$cand"
    return 0
  fi
  return 1
}

# Fail fast when the genuine wget cannot be discovered.
REAL_WGET="$(find_real wget)" || { echo "real wget not found" >&2; exit 1; }

# Load GITHUB_TOKEN from BuildKit secret if not already provided.
if [ "${GITHUB_TOKEN:-}" = "" ] && [ -f /run/secrets/GITHUB_TOKEN ]; then
  token_from_secret="$(tr -d '\r\n' < /run/secrets/GITHUB_TOKEN 2>/dev/null || true)"
  if [ "${token_from_secret:-}" != "" ]; then
    GITHUB_TOKEN="$token_from_secret"
  fi
fi

# Decide if we should append an Authorization header (via --header) for GitHub domains.
# Simplified logic: inject token if GITHUB_TOKEN exists and any URL is a GitHub domain.
# This avoids complex parsing of existing headers which is error-prone in POSIX sh.
should_add_auth=0
if [ "${GITHUB_TOKEN:-}" != "" ]; then
  # Look for a GitHub-like URL in args
  for candidate in "$@"; do
    case "$candidate" in
      https://github.com/*|https://api.github.com/*|https://raw.githubusercontent.com/*|https://objects.githubusercontent.com/*)
        should_add_auth=1
        break
        ;;
    esac
  done
fi
AUTH_HEADER_VALUE=""
if [ $should_add_auth -eq 1 ]; then
  AUTH_HEADER_VALUE="Authorization: Bearer $GITHUB_TOKEN"
fi

# Execute the real wget binary, optionally injecting our synthesized Authorization header.
run_real_wget() {
  if [ $should_add_auth -eq 1 ]; then
    "$REAL_WGET" --header="$AUTH_HEADER_VALUE" "$@"
  else
    "$REAL_WGET" "$@"
  fi
}

# Minimal POSIX arg parsing for -O/-o and capturing a single URL.
OUT=""
URL=""
NONOPT_COUNT=0
USE_CAP_O=0
SKIP_NEXT=0

i=1
while [ $i -le $# ]; do
  eval a="\${$i}"
  
  if [ $SKIP_NEXT -eq 1 ]; then
    SKIP_NEXT=0
    i=$((i+1))
    continue
  fi
  
  case "$a" in
    --tries|--waitretry|--connect-timeout)
      # Options that take a value
      SKIP_NEXT=1
      ;;
    --tries=*|--waitretry=*|--connect-timeout=*)
      # Options with = sign
      ;;
    -q|-Q)
      # Quiet mode
      ;;
    -O)
      # -O takes the next arg as output
      i=$((i+1))
      eval OUT="\${$i:-}"
      ;;
    -O*)
      # -Ooutput
      OUT="${a#-O}"
      ;;
    *O)
      # handles combined short options ending with O like -qO -> next arg is output
      i=$((i+1))
      eval OUT="\${$i:-}"
      ;;
    *O-*)
      # handles combined short options like -qO- -> output to stdout
      OUT="-"
      ;;
    -o|--output)
      i=$((i+1))
      eval OUT="\${$i:-}"
      ;;
    -o*)
      OUT="${a#-o}"
      ;;
    --output=*)
      OUT="${a#--output=}"
      ;;
    -* )
      ;;
    *)
      URL="$a"
      NONOPT_COUNT=$((NONOPT_COUNT+1))
      ;;
  esac
  i=$((i+1))
done

# Delegate to real wget when we can't safely apply caching (multiple URLs, etc.).
if [ "${URL:-}" = "" ] || [ $NONOPT_COUNT -ne 1 ]; then
  run_real_wget "$@"
  exit $?
fi

# If the caller requested output to stdout (OUT='-'), delegate so pipe-based flows still work.
if [ "${OUT:-}" = "-" ]; then
  run_real_wget "$@"
  exit $?
fi

if [ $USE_CAP_O -eq 1 ] && [ "${OUT:-}" = "" ]; then
  OUT=$(basename "${URL%%\?*}")
fi

# If no explicit output specified, wget uses basename of URL by default.
if [ "${OUT:-}" = "" ]; then
  OUT=$(basename "${URL%%\?*}")
fi


# Compute cache key using the strongest available hash utility.
if command -v sha256sum >/dev/null 2>&1; then
  KEY=$(printf '%s' "$URL" | sha256sum | awk '{print $1}')
elif command -v shasum >/dev/null 2>&1; then
  KEY=$(printf '%s' "$URL" | shasum -a 256 | awk '{print $1}')
elif command -v md5sum >/dev/null 2>&1; then
  KEY=$(printf '%s' "$URL" | md5sum | awk '{print $1}')
else
  run_real_wget "$@"
  exit $?
fi

CACHE_FILE="$CACHE_DIR/$KEY"
# Use a temporary file to keep downloads safe until cache promotion succeeds.
TMP_FILE="$(mktemp)"


# Handle absolute vs relative output paths
if [ "${OUT#/}" != "$OUT" ]; then
  # Already absolute (starts with /)
  OUT_PATH="$OUT"
else
  # Relative path, make it absolute
  OUT_PATH="$(pwd)/$OUT"
fi

# If cached, copy the artifact and exit quickly.
if [ -f "$CACHE_FILE" ]; then
  cp -f "$CACHE_FILE" "$OUT_PATH"
  exit 0
fi

# Download into temp file, then atomically move to cache and copy to OUT_PATH.
if run_real_wget -q -O "$TMP_FILE" "$URL"; then
  mv "$TMP_FILE" "$CACHE_FILE" || {
      echo "Failed to move temp file to cache: $TMP_FILE -> $CACHE_FILE" >&2
      rm -f "$TMP_FILE" || true
      exit 2
  }
  # Ensure write is flushed
  sync || true

  # Copy to requested output (absolute path) so dpkg sees it
  cp -f "$CACHE_FILE" "$OUT_PATH" || {
      echo "Failed to copy cache to output: $CACHE_FILE -> $OUT_PATH" >&2
      exit 3
  }

  # Ensure readable permissions
  chmod 644 "$OUT_PATH" || true

  exit 0
else
  rm -f "$TMP_FILE" || true
  run_real_wget "$@"
  exit $?
fi
